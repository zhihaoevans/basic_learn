#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Scrapyç¤ºä¾‹è¿è¡Œè„šæœ¬

è¿™ä¸ªè„šæœ¬æä¾›äº†ä¸€ä¸ªç®€å•çš„æ–¹å¼æ¥è¿è¡Œæ‰€æœ‰çš„Scrapyç¤ºä¾‹çˆ¬è™«ã€‚
å¯ä»¥é€‰æ‹©è¿è¡Œå•ä¸ªçˆ¬è™«æˆ–æ‰€æœ‰çˆ¬è™«ã€‚
"""

import os
import sys
import subprocess
import time
from pathlib import Path


class ScrapyRunner:
    """Scrapyçˆ¬è™«è¿è¡Œå™¨"""
    
    def __init__(self):
        self.spiders = {
            'quotes': {
                'name': 'quotes',
                'description': 'åŸºç¡€çˆ¬è™« - æŠ“å–åè¨€ç½‘ç«™',
                'output': 'quotes.json'
            },
            'quotes_js': {
                'name': 'quotes_js',
                'description': 'JavaScripté¡µé¢çˆ¬è™«',
                'output': 'quotes_js.json'
            },
            'quotes_api': {
                'name': 'quotes_api',
                'description': 'APIæ•°æ®çˆ¬è™«',
                'output': 'quotes_api.json'
            },
            'books': {
                'name': 'books',
                'description': 'ä¹¦ç±ä¿¡æ¯çˆ¬è™« - å¤æ‚æ•°æ®æå–',
                'output': 'books.json'
            },
            'books_category': {
                'name': 'books_category',
                'description': 'åˆ†ç±»ä¹¦ç±çˆ¬è™«',
                'output': 'books_category.json'
            },
            'login_spider': {
                'name': 'login_spider',
                'description': 'ç™»å½•çˆ¬è™«ç¤ºä¾‹',
                'output': 'login_data.json'
            },
            'ajax_spider': {
                'name': 'ajax_spider',
                'description': 'AJAXè¯·æ±‚çˆ¬è™«',
                'output': 'ajax_data.json'
            },
            'file_download': {
                'name': 'file_download',
                'description': 'æ–‡ä»¶ä¸‹è½½çˆ¬è™«',
                'output': 'downloads.json'
            },
            'proxy_spider': {
                'name': 'proxy_spider',
                'description': 'ä»£ç†ä½¿ç”¨ç¤ºä¾‹',
                'output': 'proxy_test.json'
            },
            'cookie_spider': {
                'name': 'cookie_spider',
                'description': 'Cookieå¤„ç†ç¤ºä¾‹',
                'output': 'cookie_test.json'
            },
            'headers_spider': {
                'name': 'headers_spider',
                'description': 'è¯·æ±‚å¤´å¤„ç†ç¤ºä¾‹',
                'output': 'headers_test.json'
            },
            'error_handling': {
                'name': 'error_handling',
                'description': 'é”™è¯¯å¤„ç†ç¤ºä¾‹',
                'output': 'error_test.json'
            }
        }
        
    def list_spiders(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„çˆ¬è™«"""
        print("\n=== å¯ç”¨çš„Scrapyçˆ¬è™«ç¤ºä¾‹ ===")
        print(f"{'åºå·':<4} {'çˆ¬è™«åç§°':<20} {'æè¿°':<30}")
        print("-" * 60)
        
        for i, (key, spider) in enumerate(self.spiders.items(), 1):
            print(f"{i:<4} {spider['name']:<20} {spider['description']:<30}")
        
        print("\n0    all                  è¿è¡Œæ‰€æœ‰çˆ¬è™«")
        print("-" * 60)
    
    def run_spider(self, spider_name, output_file=None, extra_args=None):
        """è¿è¡Œå•ä¸ªçˆ¬è™«"""
        print(f"\nğŸš€ æ­£åœ¨è¿è¡Œçˆ¬è™«: {spider_name}")
        
        # æ„å»ºå‘½ä»¤
        cmd = ['scrapy', 'crawl', spider_name]
        
        # æ·»åŠ è¾“å‡ºæ–‡ä»¶
        if output_file:
            cmd.extend(['-o', output_file])
        
        # æ·»åŠ é¢å¤–å‚æ•°
        if extra_args:
            cmd.extend(extra_args)
        
        # æ·»åŠ æ—¥å¿—çº§åˆ«
        cmd.extend(['-L', 'INFO'])
        
        print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        try:
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # è¿è¡Œçˆ¬è™«
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            # è®¡ç®—è¿è¡Œæ—¶é—´
            duration = time.time() - start_time
            
            if result.returncode == 0:
                print(f"âœ… çˆ¬è™« {spider_name} è¿è¡ŒæˆåŠŸ! è€—æ—¶: {duration:.2f}ç§’")
                if output_file and os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file} (å¤§å°: {file_size} å­—èŠ‚)")
            else:
                print(f"âŒ çˆ¬è™« {spider_name} è¿è¡Œå¤±è´¥!")
                print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                
            return result.returncode == 0
            
        except subprocess.TimeoutExpired:
            print(f"â° çˆ¬è™« {spider_name} è¿è¡Œè¶…æ—¶ (5åˆ†é’Ÿ)")
            return False
        except Exception as e:
            print(f"ğŸ’¥ è¿è¡Œçˆ¬è™«æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return False
    
    def run_all_spiders(self):
        """è¿è¡Œæ‰€æœ‰çˆ¬è™«"""
        print("\nğŸ¯ å¼€å§‹è¿è¡Œæ‰€æœ‰çˆ¬è™«ç¤ºä¾‹...")
        
        success_count = 0
        total_count = len(self.spiders)
        
        for spider_key, spider_info in self.spiders.items():
            spider_name = spider_info['name']
            output_file = spider_info['output']
            
            # ä¸ºæŸäº›çˆ¬è™«æ·»åŠ ç‰¹æ®Šå‚æ•°
            extra_args = []
            if spider_name == 'books_search':
                extra_args = ['-a', 'query=python']
            
            success = self.run_spider(spider_name, output_file, extra_args)
            if success:
                success_count += 1
            
            # åœ¨çˆ¬è™«ä¹‹é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
            time.sleep(2)
        
        print(f"\nğŸ“Š è¿è¡Œå®Œæˆ! æˆåŠŸ: {success_count}/{total_count}")
    
    def interactive_mode(self):
        """äº¤äº’å¼æ¨¡å¼"""
        while True:
            self.list_spiders()
            
            try:
                choice = input("\nè¯·é€‰æ‹©è¦è¿è¡Œçš„çˆ¬è™« (è¾“å…¥åºå·æˆ–çˆ¬è™«åç§°ï¼Œqé€€å‡º): ").strip()
                
                if choice.lower() in ['q', 'quit', 'exit']:
                    print("ğŸ‘‹ å†è§!")
                    break
                
                if choice == '0' or choice.lower() == 'all':
                    self.run_all_spiders()
                    continue
                
                # å°è¯•æŒ‰åºå·é€‰æ‹©
                if choice.isdigit():
                    spider_index = int(choice) - 1
                    if 0 <= spider_index < len(self.spiders):
                        spider_key = list(self.spiders.keys())[spider_index]
                        spider_info = self.spiders[spider_key]
                        self.run_spider(spider_info['name'], spider_info['output'])
                    else:
                        print("âŒ æ— æ•ˆçš„åºå·!")
                # å°è¯•æŒ‰åç§°é€‰æ‹©
                elif choice in self.spiders:
                    spider_info = self.spiders[choice]
                    self.run_spider(spider_info['name'], spider_info['output'])
                else:
                    # ç›´æ¥ä½œä¸ºçˆ¬è™«åç§°
                    spider_names = [info['name'] for info in self.spiders.values()]
                    if choice in spider_names:
                        self.run_spider(choice, f"{choice}.json")
                    else:
                        print("âŒ æœªæ‰¾åˆ°æŒ‡å®šçš„çˆ¬è™«!")
                        
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
                break
            except Exception as e:
                print(f"ğŸ’¥ å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ•·ï¸  Scrapy ç¤ºä¾‹çˆ¬è™«è¿è¡Œå™¨")
    print("=" * 50)
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
    if not os.path.exists('scrapy.cfg'):
        print("âŒ é”™è¯¯: è¯·åœ¨Scrapyé¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬!")
        print("å½“å‰ç›®å½•åº”è¯¥åŒ…å« scrapy.cfg æ–‡ä»¶")
        sys.exit(1)
    
    # æ£€æŸ¥Scrapyæ˜¯å¦å®‰è£…
    try:
        subprocess.run(['scrapy', '--version'], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°Scrapyå‘½ä»¤!")
        print("è¯·å…ˆå®‰è£…Scrapy: pip install scrapy")
        sys.exit(1)
    
    runner = ScrapyRunner()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        spider_name = sys.argv[1]
        
        if spider_name == 'list':
            runner.list_spiders()
        elif spider_name == 'all':
            runner.run_all_spiders()
        else:
            # è¿è¡ŒæŒ‡å®šçš„çˆ¬è™«
            output_file = f"{spider_name}.json"
            extra_args = sys.argv[2:] if len(sys.argv) > 2 else None
            runner.run_spider(spider_name, output_file, extra_args)
    else:
        # äº¤äº’å¼æ¨¡å¼
        runner.interactive_mode()


if __name__ == '__main__':
    main()